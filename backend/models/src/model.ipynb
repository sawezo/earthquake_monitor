{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f0a7cb6d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-20T00:20:25.777637Z",
     "start_time": "2021-10-20T00:20:25.756948Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "25197c01",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-20T00:27:08.129482Z",
     "start_time": "2021-10-20T00:27:08.090401Z"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c4318f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If memory growth is enabled for a PhysicalDevice,\n",
    "# the runtime initialization will not allocate all memory on the device. \n",
    "# Memory growth cannot be configured on a PhysicalDevice with virtual devices configured.\n",
    "import tensorflow as tf\n",
    "physical_devices = tf.config.list_physical_devices('GPU') \n",
    "for device in physical_devices:\n",
    "    tf.config.experimental.set_memory_growth(device, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d22f1dd",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "166d38e6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-20T00:20:26.936021Z",
     "start_time": "2021-10-20T00:20:26.683358Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"./backend/models/src/\")\n",
    "from munge import prepare_historical_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f54226f6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-20T00:20:42.040221Z",
     "start_time": "2021-10-20T00:20:41.582726Z"
    }
   },
   "outputs": [],
   "source": [
    "df = prepare_historical_data(5, [\"Longitude\", \"Latitude\", \"Magnitude\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b980139",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-20T00:20:43.949971Z",
     "start_time": "2021-10-20T00:20:43.910021Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>magnitude</th>\n",
       "      <th>geohash</th>\n",
       "      <th>geohash_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.0</td>\n",
       "      <td>x5</td>\n",
       "      <td>385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.8</td>\n",
       "      <td>wb</td>\n",
       "      <td>358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.2</td>\n",
       "      <td>2h</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.8</td>\n",
       "      <td>5m</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.8</td>\n",
       "      <td>wf</td>\n",
       "      <td>362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23407</th>\n",
       "      <td>5.6</td>\n",
       "      <td>9q</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23408</th>\n",
       "      <td>5.5</td>\n",
       "      <td>9q</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23409</th>\n",
       "      <td>5.9</td>\n",
       "      <td>xn</td>\n",
       "      <td>391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23410</th>\n",
       "      <td>6.3</td>\n",
       "      <td>qw</td>\n",
       "      <td>260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23411</th>\n",
       "      <td>5.5</td>\n",
       "      <td>xn</td>\n",
       "      <td>391</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23412 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       magnitude geohash  geohash_idx\n",
       "0            6.0      x5          385\n",
       "1            5.8      wb          358\n",
       "2            6.2      2h           17\n",
       "3            5.8      5m           50\n",
       "4            5.8      wf          362\n",
       "...          ...     ...          ...\n",
       "23407        5.6      9q           99\n",
       "23408        5.5      9q           99\n",
       "23409        5.9      xn          391\n",
       "23410        6.3      qw          260\n",
       "23411        5.5      xn          391\n",
       "\n",
       "[23412 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36db51f3",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e07f1237",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-20T00:38:23.760060Z",
     "start_time": "2021-10-20T00:38:23.723365Z"
    }
   },
   "outputs": [],
   "source": [
    "import training as train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "15f63d33",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-20T00:38:31.434832Z",
     "start_time": "2021-10-20T00:38:31.392011Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[385],\n",
       "       [358],\n",
       "       [ 17],\n",
       "       ...,\n",
       "       [391],\n",
       "       [260],\n",
       "       [391]], dtype=int16)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = train.get_y(df)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a83cb1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-26T05:16:02.716762Z",
     "start_time": "2021-09-26T05:16:02.714487Z"
    }
   },
   "outputs": [],
   "source": [
    "# for plotting... (x axis)\n",
    "# date_train = time_range[:split_idx]\n",
    "# date_test = time_range[split_idx:]\n",
    "# len(date_train), len(date_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0a640393",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-20T00:29:18.134303Z",
     "start_time": "2021-10-20T00:29:17.840867Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TT SPLIT: 0.7 | MEMORY: 1 | COMMON BATCH SIZES: {2341}\n",
      "TT SPLIT: 0.71 | MEMORY: 2 | COMMON BATCH SIZES: {4}\n",
      "TT SPLIT: 0.71 | MEMORY: 6 | COMMON BATCH SIZES: {8}\n",
      "TT SPLIT: 0.72 | MEMORY: 1 | COMMON BATCH SIZES: {5}\n",
      "TT SPLIT: 0.72 | MEMORY: 6 | COMMON BATCH SIZES: {25, 10, 50}\n",
      "TT SPLIT: 0.73 | MEMORY: 2 | COMMON BATCH SIZES: {8, 16, 4}\n",
      "TT SPLIT: 0.75 | MEMORY: 1 | COMMON BATCH SIZES: {2}\n",
      "TT SPLIT: 0.75 | MEMORY: 3 | COMMON BATCH SIZES: {6}\n",
      "TT SPLIT: 0.76 | MEMORY: 1 | COMMON BATCH SIZES: {2}\n",
      "TT SPLIT: 0.76 | MEMORY: 3 | COMMON BATCH SIZES: {6}\n",
      "TT SPLIT: 0.77 | MEMORY: 1 | COMMON BATCH SIZES: {2}\n",
      "TT SPLIT: 0.77 | MEMORY: 2 | COMMON BATCH SIZES: {7}\n",
      "TT SPLIT: 0.77 | MEMORY: 3 | COMMON BATCH SIZES: {6}\n",
      "TT SPLIT: 0.77 | MEMORY: 9 | COMMON BATCH SIZES: {42, 21, 14}\n",
      "TT SPLIT: 0.78 | MEMORY: 1 | COMMON BATCH SIZES: {2, 10, 5}\n",
      "TT SPLIT: 0.78 | MEMORY: 2 | COMMON BATCH SIZES: {19}\n",
      "TT SPLIT: 0.78 | MEMORY: 3 | COMMON BATCH SIZES: {6}\n",
      "TT SPLIT: 0.78 | MEMORY: 6 | COMMON BATCH SIZES: {15}\n",
      "TT SPLIT: 0.79 | MEMORY: 1 | COMMON BATCH SIZES: {2}\n",
      "TT SPLIT: 0.79 | MEMORY: 3 | COMMON BATCH SIZES: {6}\n",
      "TT SPLIT: 0.8 | MEMORY: 1 | COMMON BATCH SIZES: {2, 2341, 4682}\n",
      "TT SPLIT: 0.8 | MEMORY: 3 | COMMON BATCH SIZES: {6}\n",
      "TT SPLIT: 0.81 | MEMORY: 1 | COMMON BATCH SIZES: {2}\n",
      "TT SPLIT: 0.81 | MEMORY: 3 | COMMON BATCH SIZES: {6}\n",
      "TT SPLIT: 0.82 | MEMORY: 1 | COMMON BATCH SIZES: {2}\n",
      "TT SPLIT: 0.82 | MEMORY: 2 | COMMON BATCH SIZES: {11}\n",
      "TT SPLIT: 0.82 | MEMORY: 3 | COMMON BATCH SIZES: {6}\n",
      "TT SPLIT: 0.83 | MEMORY: 1 | COMMON BATCH SIZES: {2, 10, 5}\n",
      "TT SPLIT: 0.83 | MEMORY: 3 | COMMON BATCH SIZES: {6}\n",
      "TT SPLIT: 0.83 | MEMORY: 6 | COMMON BATCH SIZES: {25, 75, 15}\n",
      "TT SPLIT: 0.84 | MEMORY: 1 | COMMON BATCH SIZES: {5}\n",
      "TT SPLIT: 0.84 | MEMORY: 2 | COMMON BATCH SIZES: {8, 16, 4}\n",
      "TT SPLIT: 0.84 | MEMORY: 6 | COMMON BATCH SIZES: {10, 20}\n",
      "TT SPLIT: 0.86 | MEMORY: 2 | COMMON BATCH SIZES: {4, 28, 14, 7}\n",
      "TT SPLIT: 0.86 | MEMORY: 6 | COMMON BATCH SIZES: {8}\n",
      "TT SPLIT: 0.88 | MEMORY: 2 | COMMON BATCH SIZES: {8, 4}\n",
      "TT SPLIT: 0.89 | MEMORY: 1 | COMMON BATCH SIZES: {5}\n",
      "TT SPLIT: 0.89 | MEMORY: 2 | COMMON BATCH SIZES: {11, 22}\n",
      "TT SPLIT: 0.89 | MEMORY: 3 | COMMON BATCH SIZES: {83}\n",
      "TT SPLIT: 0.89 | MEMORY: 6 | COMMON BATCH SIZES: {10}\n"
     ]
    }
   ],
   "source": [
    "# need to choose batch size so that n/batch_size remainder is memory (timesteps/events looking back)\n",
    "# want larger batch size for model performance so wrote wrapper func to help find\n",
    "\n",
    "\n",
    "# train/test split\n",
    "for train_proportion in list(range(70, 90, 1)):\n",
    "    train_proportion /= 100\n",
    "    split_idx = int(train_proportion*len(y))\n",
    "    geo_train = y[:split_idx]\n",
    "    geo_test = y[split_idx:]\n",
    "\n",
    "\n",
    "    for MEMORY in list(range(1, 10)):\n",
    "        def print_factors(data_ct, MEMORY):\n",
    "            return {batch_size for batch_size in range(1, data_ct+1) \n",
    "                        if data_ct % batch_size == MEMORY}\n",
    "\n",
    "        train_batch_sizes = print_factors(len(geo_train), MEMORY)\n",
    "        test_batch_sizes = print_factors(len(geo_test), MEMORY)\n",
    "\n",
    "\n",
    "        common_sizes = train_batch_sizes.intersection(test_batch_sizes)\n",
    "        if len(common_sizes)>=1:\n",
    "            print(f\"TT SPLIT: {train_proportion} | MEMORY: {MEMORY} | COMMON BATCH SIZES: {common_sizes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a6eed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tt_split(y, train_proportion=.77)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "96cac370",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-20T00:29:25.778184Z",
     "start_time": "2021-10-20T00:29:25.741481Z"
    }
   },
   "outputs": [],
   "source": [
    "MEMORY = 9\n",
    "BATCH_SIZE = 42\n",
    "\n",
    "train_generator = TimeseriesGenerator(geo_train, geo_train, length=MEMORY, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d0fbb05b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-20T00:30:39.817299Z",
     "start_time": "2021-10-20T00:30:39.697322Z"
    }
   },
   "outputs": [],
   "source": [
    "DROPOUT = .6\n",
    "EPOCHS = 10\n",
    "ACTIVATION = \"tanh\"\n",
    "ALPHA = 1e-06\n",
    "UNITS = 64\n",
    "CLASS_COUNT = len(np.unique(y))\n",
    "feature_ct = geo_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c190dffd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-20T00:30:41.460564Z",
     "start_time": "2021-10-20T00:30:40.584372Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer input_lstm will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_lstm (LSTM)            (42, 9, 64)               16896     \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (42, 64)                  33024     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (42, 64)                  0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (42, 424)                 27560     \n",
      "=================================================================\n",
      "Total params: 77,480\n",
      "Trainable params: 77,480\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# did not 1-hot encode since using  sparse loss\n",
    "batchsize__input_dim = (BATCH_SIZE, MEMORY, feature_ct) \n",
    "model.add(LSTM(UNITS, \n",
    "               activation=ACTIVATION, \n",
    "               batch_input_shape=batchsize__input_dim, \n",
    "               return_sequences=True, \n",
    "               stateful=True, \n",
    "               name=\"input_lstm\",\n",
    "               recurrent_dropout=DROPOUT\n",
    "              )) \n",
    "\n",
    "model.add(LSTM(UNITS, \n",
    "               activation=ACTIVATION,\n",
    "               recurrent_dropout=DROPOUT,\n",
    "               return_sequences=False,\n",
    "              ))\n",
    "\n",
    "model.add(Dropout(DROPOUT))\n",
    "\n",
    "model.add(Dense(CLASS_COUNT, activation=\"softmax\"))\n",
    "\n",
    "\n",
    "def top_k_metric(y_true, y_pred):\n",
    "    return top_k_categorical_accuracy(y_true, y_pred, k=10) \n",
    "\n",
    "\n",
    "optimizer = Adam(learning_rate=ALPHA)\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, \n",
    "              sample_weight_mode=\"temporal\",\n",
    "              metrics=[top_k_metric, \"sparse_categorical_accuracy\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d363e0e1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-20T00:33:04.592888Z",
     "start_time": "2021-10-20T00:30:51.879577Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-19 20:30:52.637147: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2021-10-19 20:30:52.670645: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 3494665000 Hz\n",
      "2021-10-19 20:31:00.944460: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "429/429 [==============================] - 30s 45ms/step - loss: 6.0595 - top_k_metric: 0.0161 - sparse_categorical_accuracy: 0.0026\n",
      "\n",
      "429/429 [==============================] - 11s 27ms/step - loss: 6.0530 - top_k_metric: 0.0154 - sparse_categorical_accuracy: 0.0027\n",
      "\n",
      "429/429 [==============================] - 11s 26ms/step - loss: 6.0477 - top_k_metric: 0.0164 - sparse_categorical_accuracy: 0.0023\n",
      "\n",
      "429/429 [==============================] - 11s 25ms/step - loss: 6.0411 - top_k_metric: 0.0152 - sparse_categorical_accuracy: 0.0023\n",
      "\n",
      "429/429 [==============================] - 11s 26ms/step - loss: 6.0387 - top_k_metric: 0.0138 - sparse_categorical_accuracy: 0.0029\n",
      "\n",
      "429/429 [==============================] - 11s 26ms/step - loss: 6.0311 - top_k_metric: 0.0133 - sparse_categorical_accuracy: 0.0042\n",
      "\n",
      "429/429 [==============================] - 11s 25ms/step - loss: 6.0260 - top_k_metric: 0.0137 - sparse_categorical_accuracy: 0.0043\n",
      "\n",
      "429/429 [==============================] - 12s 29ms/step - loss: 6.0238 - top_k_metric: 0.0113 - sparse_categorical_accuracy: 0.0044\n",
      "\n",
      "429/429 [==============================] - 12s 27ms/step - loss: 6.0161 - top_k_metric: 0.0124 - sparse_categorical_accuracy: 0.0056\n",
      "\n",
      "429/429 [==============================] - 11s 25ms/step - loss: 6.0125 - top_k_metric: 0.0107 - sparse_categorical_accuracy: 0.0053\n"
     ]
    }
   ],
   "source": [
    "for i in range(EPOCHS):\n",
    "    print()\n",
    "    \n",
    "    model.fit_generator(train_generator, epochs=1, shuffle=False)\n",
    "    model.reset_states()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13d00ce7",
   "metadata": {},
   "source": [
    "One big difference between regular regression models and time series models is how we run predictions. The first one should be pretty obvious, we take the last 12 months of train data and predict it to get the first test data.\n",
    "How do we predict the next one?\n",
    "This is a big issue esp. if you take a shortcut and use the test data’s first value and use that as your last prediction. That way you are feeding the correct values for the prior steps helping the model to create better results that it would otherwise give.\n",
    "What needs to happen is that the “first prediction” needs to be added to the last 11 training data to create a new set of 12 data points to predict the next one. This way we are not cheating at all, the test data is really test data and is never seen by the model.\n",
    "\n",
    "this post wasn't worth saving tho..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32db139a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-26T05:23:41.333790Z",
     "start_time": "2021-09-26T05:23:40.426758Z"
    }
   },
   "outputs": [],
   "source": [
    "# trimming slightly to fit batch size\n",
    "test_generator = TimeseriesGenerator(geo_test, geo_test, length=MEMORY, batch_size=BATCH_SIZE)\n",
    "prediction = model.predict_generator(test_generator, verbose=1)\n",
    "prediction.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9358a0cf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-26T05:23:42.149501Z",
     "start_time": "2021-09-26T05:23:42.141790Z"
    }
   },
   "outputs": [],
   "source": [
    "max_index_col = np.argmax(prediction, axis=1)\n",
    "set(max_index_col) # the different indices that were max (output neurons that lit up the most)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc5b672",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-26T05:24:21.552263Z",
     "start_time": "2021-09-26T05:24:21.528429Z"
    }
   },
   "outputs": [],
   "source": [
    "lat__long = [gh.decode(geohash_idx2hash[e]) for e in max_index_col] # make sure right way around!\n",
    "# make sure proper order\n",
    "# make sure unpacks index per model lines up. MOVE ON IGNORE DEETS!\n",
    "prediction_df = pd.DataFrame(lat__long, columns=[\"latitude\", \"longitude\"])\n",
    "prediction_df.drop_duplicates(inplace=True)\n",
    "prediction_df.reset_index(drop=True)\n",
    "prediction_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e86a62",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-26T05:27:13.227153Z",
     "start_time": "2021-09-26T05:27:13.059771Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(x=prediction_df['longitude'], y=prediction_df['latitude'], color=\"red\")\n",
    "\n",
    "huh = df[[\"Latitude\", \"Longitude\"]].drop_duplicates()\n",
    "plt.scatter(x=huh['Longitude'], y=huh['Latitude'], color=\"green\", alpha=.01)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44cfe642",
   "metadata": {},
   "source": [
    "Assuming that the algorithms have a hard time to interpret GPS coordinates, the system\n",
    "could instead use encoded positions. This approach would take a latitude and longitude position and with a defined precision hash it and save it in a dictionary. This precision would\n",
    "be the amount of decimals for the latitude and longitude to use. This would discretize the\n",
    "operating area into a grid where the interval depends on the chosen precision.\n",
    "The drawback of this approach is with higher precision and operating area, the exponentially more locations have to hashed and stored. A small area of radius ten kilometre and\n",
    "4 decimal precision could yield well over 300000 locations and therefore outcomes. Another\n",
    "drawback is that the algorithm can only use positions it have trained on.\n",
    "\n",
    "\n",
    "need to 1-hjot encode since no ordinal relation exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "071e2aa3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-19T21:55:40.947766Z",
     "start_time": "2021-10-19T21:55:40.944879Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"./backend/src/\")\n",
    "import utils, json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6f061b89",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-19T21:57:02.008705Z",
     "start_time": "2021-10-19T21:57:01.998558Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(\"./backend/src/dev/test.json\", \"r\") as infile:\n",
    "    data = json.load(infile)\n",
    "df = utils.frame_data([utils.flatten_json(q) for q in data[\"features\"]], keep2rename = {'properties>mag':'magnitude',\n",
    "               'properties>sig':'significance',\n",
    "               'geometry>coordinates>0':'longitude',\n",
    "               'geometry>coordinates>1':'latitude',\n",
    "               'geometry>coordinates>2':'depth'}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6d4d5a45",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-19T21:57:12.217570Z",
     "start_time": "2021-10-19T21:57:12.208572Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.78, 0.86, 2.43, 1.9 , 1.84, 0.98, 1.18, 0.94, 2.88, 0.84, 2.19,\n",
       "       1.93, 1.  ])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"magnitude\"].unique()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:quake_back_end]",
   "language": "python",
   "name": "conda-env-quake_back_end-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
